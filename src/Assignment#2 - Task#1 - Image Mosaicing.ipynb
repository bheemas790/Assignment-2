{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Mosaicing\n",
    "\n",
    "1. Use any feature detector and descriptor (e.g. SIFT) to find matches between two\n",
    "partially overlapping images. You can use inbuilt functions for this.\n",
    "2. Estimate the homography matrix between the two images robustly.\n",
    "3. Transform one of the images to the otherâ€™s reference frame using the homography\n",
    "matrix.\n",
    "4. Stitch the two images together.\n",
    "5. Repeat this for multiple images to produce a singly mosaic/panorama.\n",
    "6. Demonstrate the results on different scenes from the given data.\n",
    "7. Additionally, capture a set of overlapping images of a scene with your camera and\n",
    "report the results on the same.\n",
    "8. BONUS: Think of an algorithm which can stitch images given in any order without\n",
    "human intervention. Modify your existing code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mosaicing:\n",
    "\n",
    "    def stich_images(self, images, lowe_ratio=0.5, max_Threshold=2.0,match_status=False):\n",
    "\n",
    "        #detect the features and keypoints from SIFT\n",
    "        (imageB, imageA) = images\n",
    "        (KeypointsA, features_of_A) = self.Find_Feature_And_KeyPoints(imageA)\n",
    "        (KeypointsB, features_of_B) = self.Find_Feature_And_KeyPoints(imageB)\n",
    "\n",
    "        #got the valid matched points\n",
    "        Values = self.matchKeypoints(KeypointsA, KeypointsB,features_of_A, features_of_B, lowe_ratio, max_Threshold)\n",
    "\n",
    "        if Values is None:\n",
    "            return None\n",
    "\n",
    "        #to get perspective of image using computed homography\n",
    "        (matches, Homography, status) = Values\n",
    "        result_image = self.getwarp_perspective(imageA,imageB,Homography)\n",
    "        result_image[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n",
    "\n",
    "        # check to see if the keypoint matches should be visualized\n",
    "        if match_status:\n",
    "            vis = self.draw_Matches(imageA, imageB, KeypointsA, KeypointsB, matches,status)\n",
    "\n",
    "            return (result_image, vis)\n",
    "\n",
    "        return result_image\n",
    "\n",
    "    def getwarp_perspective(self,imageA,imageB,Homography):\n",
    "        val = imageA.shape[1] + imageB.shape[1]\n",
    "        result_image = cv2.warpPerspective(imageA, Homography, (val , imageA.shape[0]))\n",
    "\n",
    "        return result_image\n",
    "\n",
    "    def Find_Feature_And_KeyPoints(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect and extract features from the image\n",
    "        descriptors = cv2.xfeatures2d.SIFT_create()\n",
    "        (Keypoints, features) = descriptors.detectAndCompute(image, None)\n",
    "\n",
    "        Keypoints = np.float32([i.pt for i in Keypoints])\n",
    "        return (Keypoints, features)\n",
    "\n",
    "    def get_Allpossible_Match(self,featuresA,featuresB):\n",
    "\n",
    "        # compute the all matches using euclidean distance and opencv provide\n",
    "        #DescriptorMatcher_create() function for that\n",
    "        match_instance = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "        All_Matches = match_instance.knnMatch(featuresA, featuresB, 2)\n",
    "\n",
    "        return All_Matches\n",
    "\n",
    "    def All_validmatches(self,AllMatches,lowe_ratio):\n",
    "        #to get all valid matches according to lowe concept..\n",
    "        valid_matches = []\n",
    "\n",
    "        for val in AllMatches:\n",
    "            if len(val) == 2 and val[0].distance < val[1].distance * lowe_ratio:\n",
    "                valid_matches.append((val[0].trainIdx, val[0].queryIdx))\n",
    "\n",
    "        return valid_matches\n",
    "\n",
    "    def Compute_Homography(self,pointsA,pointsB,max_Threshold):\n",
    "        #to compute homography using points in both images\n",
    "\n",
    "        (H, status) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC, max_Threshold)\n",
    "        return (H,status)\n",
    "\n",
    "    def matchKeypoints(self, KeypointsA, KeypointsB, featuresA, featuresB,lowe_ratio, max_Threshold):\n",
    "\n",
    "        AllMatches = self.get_Allpossible_Match(featuresA,featuresB);\n",
    "        valid_matches = self.All_validmatches(AllMatches,lowe_ratio)\n",
    "\n",
    "        if len(valid_matches) > 4:\n",
    "            # construct the two sets of points\n",
    "            pointsA = np.float32([KeypointsA[i] for (_,i) in valid_matches])\n",
    "            pointsB = np.float32([KeypointsB[i] for (i,_) in valid_matches])\n",
    "\n",
    "            (Homograpgy, status) = self.Compute_Homography(pointsA, pointsB, max_Threshold)\n",
    "\n",
    "            return (valid_matches, Homograpgy, status)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_image_dimension(self,image):\n",
    "        (h,w) = image.shape[:2]\n",
    "        return (h,w)\n",
    "\n",
    "    def get_points(self,imageA,imageB):\n",
    "\n",
    "        (hA, wA) = self.get_image_dimension(imageA)\n",
    "        (hB, wB) = self.get_image_dimension(imageB)\n",
    "        vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n",
    "        vis[0:hA, 0:wA] = imageA\n",
    "        vis[0:hB, wA:] = imageB\n",
    "\n",
    "        return vis\n",
    "\n",
    "\n",
    "    def draw_Matches(self, imageA, imageB, KeypointsA, KeypointsB, matches, status):\n",
    "\n",
    "        (hA,wA) = self.get_image_dimension(imageA)\n",
    "        vis = self.get_points(imageA,imageB)\n",
    "\n",
    "        # loop over the matches\n",
    "        for ((trainIdx, queryIdx), s) in zip(matches, status):\n",
    "            if s == 1:\n",
    "                ptA = (int(KeypointsA[queryIdx][0]), int(KeypointsA[queryIdx][1]))\n",
    "                ptB = (int(KeypointsB[trainIdx][0]) + wA, int(KeypointsB[trainIdx][1]))\n",
    "                cv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n",
    "\n",
    "        return vis\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(src, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "        \n",
    "        #Utility Function: Resizes Image to new width and height\n",
    "        #Mention new width and height, else None expected.\n",
    "        #Default interpolation - INTER_AREA\n",
    "        \n",
    "        print(\"Resizing... \")\n",
    "        # set dimension to None, to return if no dimension specified\n",
    "        dim = None\n",
    "        (h, w) = src.shape[:2] # take height and width\n",
    "\n",
    "        # handle None values in width and height\n",
    "        if width is None and height is None:\n",
    "            return src \n",
    "\n",
    "        # to resize, aspect ratio has to be kept in check\n",
    "        # for no distortion of the shape of the imag3\n",
    "        if width is None:\n",
    "            # calculate aspect ratio changed according to new height\n",
    "            ratio = height / float(h)\n",
    "            # change width according to the ratio\n",
    "            dim = (int(w * ratio), height)\n",
    "        else:\n",
    "            # calculate aspect ratio changed according to new width\n",
    "            ratio = width/float(w)\n",
    "            dim = (width, int(h * ratio))\n",
    "        # apply resizing using calculated dimensions \n",
    "        result = cv2.resize(src, dim, interpolation=inter)\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images 6\n",
      "images read\n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "Resizing... \n",
      "no_of_images 6\n",
      "count 2\n",
      "count 3\n",
      "count 4\n",
      "count 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path  = \"images/Image Mosaicing/\"  # Path to input images\n",
    "# Enter image names to stich in the images_list as below\n",
    "images_list = [\"6_1.jpg\", \"6_2.jpg\", \"6_3.jpg\",\"6_4.jpg\", \"6_5.jpg\", \"6_6.jpg\"]\n",
    "images_list = [path + x for x in images_list]\n",
    "no_of_images = len(images_list)\n",
    "print('number of images', no_of_images)\n",
    "images = []\n",
    "#print(images_list)\n",
    "for i in range(no_of_images):\n",
    "    images.append(cv2.imread(images_list[i])) # read images from given path\n",
    "print('images read')\n",
    "#print(images[0])\n",
    "#We need to modify the image resolution and keep our aspect ratio  \n",
    "\n",
    "for i in range(no_of_images):\n",
    "    images[i] = resize(images[i], width=400)\n",
    "\n",
    "for i in range(no_of_images):\n",
    "    images[i] = resize(images[i], height=400)\n",
    "count = 0\n",
    "image_mosaicing = Mosaicing()\n",
    "if no_of_images==2:\n",
    "    #(result) = image_mosaicing.stich_images([images[0], images[1]], match_status=True)\n",
    "    (result, matched_points) = image_mosaicing.stich_images([images[0], images[1]], match_status=True)\n",
    "else:\n",
    "    print('no_of_images', no_of_images)\n",
    "    '''\n",
    "    (result, matched_points) = image_mosaicing.stich_images([images[no_of_images-2], images[no_of_images-1]], match_status=True)\n",
    "    for i in range(no_of_images - 2):\n",
    "        print('i value',i)\n",
    "        (result, matched_points) = image_mosaicing.stich_images([images[no_of_images-i-3],result], match_status=True)\n",
    "    '''\n",
    "    (result, matched_points) = image_mosaicing.stich_images([images[0], images[1]], match_status=True)\n",
    "     \n",
    "    #cv2.imwrite(\"Image6.png\",result)\n",
    "    count = 2\n",
    "    while count < no_of_images:\n",
    "        print('count',count)\n",
    "        (result, matched_points) = image_mosaicing.stich_images([images[count], result], match_status=True)\n",
    "         \n",
    "        count = count + 1\n",
    "    \n",
    "#to write the images\n",
    "cv2.imwrite(\"Matched_points6-3.png\",matched_points)\n",
    "cv2.imwrite(\"Image_Mosaicing6-3.png\",result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All input images are tested with the code. Results are captured in\n",
    "\n",
    "Image_Mosaicing1.png\n",
    "Image_Mosaicing2.png\n",
    "Image_Mosaicing3.png\n",
    "Image_Mosaicing4.png\n",
    "Image_Mosaicing5.png\n",
    "Image_Mosaicing6-3.png (These overlapping pictures are taken from my camera. These images are captured from closer and from farther distance. It has been observed that valid matches are stiched into panorama with highest key matches.)\n",
    "\n",
    "Keypoints are captured here ->\n",
    "Matched_points1.png\n",
    "Matched_points2.png\n",
    "Matched_points3.png\n",
    "Matched_points4.png\n",
    "Matched_points5.png\n",
    "Matched_points6-3.png\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
